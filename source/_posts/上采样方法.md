---
title: 上采样方法
date: 2021-09-06 15:48:43
tags:
categories:
password:
abstract:
message:
---







# pixelshuffle

上采样可以理解为在同一个位置，原来只是以1:1的比例提取信息，而现在以1:4的比例提取信息，提取信息的频率更高了，所以能反映的细节也就更多。对于tensor来说，在同一个位置多提取信息，也就是通过卷积生成通道数更多的tensor。具体过程为（以一个（n,64,64,64）的特征图为例）

1. 通过卷积，得到通道数倍增的特征图（n,64,64,256）
2. 将特征图切割成若干份，对每一份（n,64,64,4）的像素点进行重新排列,reshape成(n,64,64,2,2），再reshape成（n,64,2,64,2），最后reshape成（n,128,128,1），再把这么多份拼接起来，得（n,128,128,64）的特征图

![image-20210906161758378](image-20210906161758378.png)

![image-20210906161922868](image-20210906161922868.png)





# upsample

插值方法



# 转置卷积(ConvTranspose2d)

填充0后做卷积



# 参考资料

[(19条消息) 上采样方法大PK（Upsample，Interpolate，resize，Transposed convolution，deconv，Unpool，Pixelshuffle）_年轻即出发，-CSDN博客](https://blog.csdn.net/qq_14845119/article/details/107557449)

[上采样，上池化，反卷积 - OliYoung - 博客园 (cnblogs.com)](https://www.cnblogs.com/oliyoung/p/upsample.html)

[PixelShuffler原理学习笔记 - 程序员大本营 (pianshen.com)](https://www.pianshen.com/article/46871443097/)

[pytorch中的上采样（上采样，转置卷积，上池化，PixelShuffle） - 那抹阳光1994 - 博客园 (cnblogs.com)](https://www.cnblogs.com/jiangkejie/p/12919155.html)

